2025-11-23T17:23:18.322711166Z     ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:23:18.322714006Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/gunicorn/workers/sync.py", line 177, in handle_request
2025-11-23T17:23:18.322716826Z     respiter = self.wsgi(environ, resp.start_response)
2025-11-23T17:23:18.322720306Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/flask/app.py", line 1536, in __call__
2025-11-23T17:23:18.322723116Z     return self.wsgi_app(environ, start_response)
2025-11-23T17:23:18.322725876Z            ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:23:18.322728736Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/flask/app.py", line 1511, in wsgi_app
2025-11-23T17:23:18.322731647Z     response = self.full_dispatch_request()
2025-11-23T17:23:18.322734467Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/flask/app.py", line 917, in full_dispatch_request
2025-11-23T17:23:18.322738067Z     rv = self.dispatch_request()
2025-11-23T17:23:18.322740847Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/flask/app.py", line 902, in dispatch_request
2025-11-23T17:23:18.322743627Z     return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
2025-11-23T17:23:18.322746457Z            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
2025-11-23T17:23:18.322749387Z   File "/opt/render/project/src/app.py", line 46, in ask_question
2025-11-23T17:23:18.322752547Z     result = service.answer_question(question, top_k=top_k)
2025-11-23T17:23:18.322770477Z   File "/opt/render/project/src/question_answering.py", line 702, in answer_question
2025-11-23T17:23:18.322772377Z     retrieved = self.index.retrieve(question, top_k=top_k)
2025-11-23T17:23:18.322774157Z   File "/opt/render/project/src/question_answering.py", line 398, in retrieve
2025-11-23T17:23:18.322776427Z     self._ensure_embeddings()
2025-11-23T17:23:18.322778147Z     ~~~~~~~~~~~~~~~~~~~~~~~^^
2025-11-23T17:23:18.322779907Z   File "/opt/render/project/src/question_answering.py", line 197, in _ensure_embeddings
2025-11-23T17:23:18.322781667Z     self.embeddings = self.embedding_backend.embed_texts(texts, task_type="retrieval_document")
2025-11-23T17:23:18.322783747Z                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:23:18.322785507Z   File "/opt/render/project/src/gemini_embeddings.py", line 52, in embed_texts
2025-11-23T17:23:18.322787297Z     result = genai.embed_content(
2025-11-23T17:23:18.322788997Z         model=self.model_name,
2025-11-23T17:23:18.322791477Z         content=text,
2025-11-23T17:23:18.322793187Z         task_type=task_type
2025-11-23T17:23:18.322794887Z     )
2025-11-23T17:23:18.322796797Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/generativeai/embedding.py", line 213, in embed_content
2025-11-23T17:23:18.322798557Z     embedding_response = client.embed_content(
2025-11-23T17:23:18.322800308Z         embedding_request,
2025-11-23T17:23:18.322802077Z         **request_options,
2025-11-23T17:23:18.322803737Z     )
2025-11-23T17:23:18.322806228Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 1263, in embed_content
2025-11-23T17:23:18.322807918Z     response = rpc(
2025-11-23T17:23:18.322809608Z         request,
2025-11-23T17:23:18.322811308Z     ...<2 lines>...
2025-11-23T17:23:18.322813008Z         metadata=metadata,
2025-11-23T17:23:18.322814698Z     )
2025-11-23T17:23:18.322816478Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
2025-11-23T17:23:18.322818198Z     return wrapped_func(*args, **kwargs)
2025-11-23T17:23:18.322820628Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
2025-11-23T17:23:18.322822388Z     return retry_target(
2025-11-23T17:23:18.322824058Z         target,
2025-11-23T17:23:18.322825728Z     ...<3 lines>...
2025-11-23T17:23:18.322827438Z         on_error=on_error,
2025-11-23T17:23:18.322829098Z     )
2025-11-23T17:23:18.322830858Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
2025-11-23T17:23:18.322832568Z     result = target()
2025-11-23T17:23:18.322834348Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
2025-11-23T17:23:18.322836108Z     return func(*args, **kwargs)
2025-11-23T17:23:18.322837778Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/api_core/grpc_helpers.py", line 75, in error_remapped_callable
2025-11-23T17:23:18.322842188Z     return callable_(*args, **kwargs)
2025-11-23T17:23:18.322844148Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/grpc/_interceptor.py", line 276, in __call__
2025-11-23T17:23:18.322845838Z     response, ignored_call = self._with_call(
2025-11-23T17:23:18.322847648Z                              ~~~~~~~~~~~~~~~^
2025-11-23T17:23:18.322852478Z         request,
2025-11-23T17:23:18.322854218Z         ^^^^^^^^
2025-11-23T17:23:18.322855888Z     ...<4 lines>...
2025-11-23T17:23:18.322857578Z         compression=compression,
2025-11-23T17:23:18.322859238Z         ^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:23:18.322860958Z     )
2025-11-23T17:23:18.322862609Z     ^
2025-11-23T17:23:18.322864309Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/grpc/_interceptor.py", line 328, in _with_call
2025-11-23T17:23:18.322868109Z     call = self._interceptor.intercept_unary_unary(
2025-11-23T17:23:18.322881579Z         continuation, client_call_details, request
2025-11-23T17:23:18.322883449Z Loading dataset from processed_data.json...
2025-11-23T17:23:18.322883609Z     )
2025-11-23T17:23:18.322886069Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py", line 79, in intercept_unary_unary
2025-11-23T17:23:18.322893619Z Dataset loaded successfully!
2025-11-23T17:23:18.322896879Z ‚úì Loaded 71 cached answers from qa_history.jsonl
2025-11-23T17:23:18.322914379Z ‚úì Gemini backend initialized (model: gemini-2.5-flash-lite)
2025-11-23T17:23:18.322918069Z ‚ö†Ô∏è GitHub fallback not available: GitHub token not found. Set GITHUB_TOKEN environment variable or pass api_key parameter. Create token at: https://github.com/settings/tokens
2025-11-23T17:23:18.322920419Z ‚è≥ Generating embeddings for 438 passages via Gemini API...
2025-11-23T17:23:18.322922539Z    This happens only once (first query), then cached in memory.
2025-11-23T17:23:18.322925199Z ‚úì Gemini Embeddings initialized (model: models/text-embedding-004)
2025-11-23T17:23:18.322927499Z   Embedded 100/438 texts...
2025-11-23T17:23:18.32293089Z 127.0.0.1 - - [23/Nov/2025:17:23:18 +0000] "POST /api/ask HTTP/1.1" 500 0 "-" "-"
2025-11-23T17:23:18.32293733Z     response = continuation(client_call_details, request)
2025-11-23T17:23:18.32294032Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/grpc/_interceptor.py", line 314, in continuation
2025-11-23T17:23:18.32294271Z     response, call = self._thunk(new_method).with_call(
2025-11-23T17:23:18.32294514Z                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
2025-11-23T17:23:18.32294755Z         request,
2025-11-23T17:23:18.32294986Z         ^^^^^^^^
2025-11-23T17:23:18.32295291Z     ...<4 lines>...
2025-11-23T17:23:18.32295538Z         compression=new_compression,
2025-11-23T17:23:18.3229578Z         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:23:18.3229599Z     )
2025-11-23T17:23:18.32296223Z     ^
2025-11-23T17:23:18.32296511Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/grpc/_channel.py", line 1177, in with_call
2025-11-23T17:23:18.32296728Z     state, call = self._blocking(
2025-11-23T17:23:18.32296947Z                   ~~~~~~~~~~~~~~^
2025-11-23T17:23:18.32297176Z         request, timeout, metadata, credentials, wait_for_ready, compression
2025-11-23T17:23:18.32297397Z         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:23:18.32297636Z     )
2025-11-23T17:23:18.32297854Z     ^
2025-11-23T17:23:18.32298112Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/grpc/_channel.py", line 1150, in _blocking
2025-11-23T17:23:18.32298321Z     event = call.next_event()
2025-11-23T17:23:18.32298543Z   File "src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi", line 388, in grpc._cython.cygrpc.SegregatedCall.next_event
2025-11-23T17:23:18.32298765Z   File "src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi", line 211, in grpc._cython.cygrpc._next_call_event
2025-11-23T17:23:18.323018861Z   File "src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi", line 205, in grpc._cython.cygrpc._next_call_event
2025-11-23T17:23:18.323030121Z   File "src/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi", line 97, in grpc._cython.cygrpc._latent_event
2025-11-23T17:23:18.323032891Z   File "src/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi", line 80, in grpc._cython.cygrpc._internal_latent_event
2025-11-23T17:23:18.323035281Z   File "src/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi", line 61, in grpc._cython.cygrpc._next
2025-11-23T17:23:18.323037911Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/gunicorn/workers/base.py", line 204, in handle_abort
2025-11-23T17:23:18.323040771Z     sys.exit(1)
2025-11-23T17:23:18.323043271Z     ~~~~~~~~^^^
2025-11-23T17:23:18.323046301Z SystemExit: 1
2025-11-23T17:23:18.323189123Z [2025-11-23 17:23:18 +0000] [65] [INFO] Worker exiting (pid: 65)
2025-11-23T17:23:19.142114208Z [2025-11-23 17:23:19 +0000] [56] [ERROR] Worker (pid:65) was sent SIGKILL! Perhaps out of memory?
2025-11-23T17:23:19.23404017Z [2025-11-23 17:23:19 +0000] [207] [INFO] Booting worker with pid: 207
2025-11-23T17:29:48.88641017Z ==> Deploying...
2025-11-23T17:30:29.518338732Z [2025-11-23 17:30:29 +0000] [56] [INFO] Listening at: http://0.0.0.0:10000 (56)
2025-11-23T17:30:29.518355913Z [2025-11-23 17:30:29 +0000] [56] [INFO] Using worker: sync
2025-11-23T17:30:29.609157941Z [2025-11-23 17:30:29 +0000] [65] [INFO] Booting worker with pid: 65
2025-11-23T17:30:30.175644744Z 127.0.0.1 - - [23/Nov/2025:17:30:30 +0000] "HEAD / HTTP/1.1" 200 0 "-" "Go-http-client/1.1"
2025-11-23T17:30:39.996062712Z ==> Your service is live üéâ
2025-11-23T17:30:40.219930844Z ==> 
2025-11-23T17:30:40.419112077Z ==> ///////////////////////////////////////////////////////////
2025-11-23T17:30:40.583634964Z ==> 
2025-11-23T17:30:40.76166197Z ==> Available at your primary URL https://home-studio-recording.onrender.com
2025-11-23T17:30:40.922175727Z ==> 
2025-11-23T17:30:41.084430084Z ==> ///////////////////////////////////////////////////////////
2025-11-23T17:30:43.253669062Z 127.0.0.1 - - [23/Nov/2025:17:30:43 +0000] "GET / HTTP/1.1" 200 4875 "-" "Go-http-client/2.0"
2025-11-23T17:31:39.311388412Z [2025-11-23 17:31:39 +0000] [56] [INFO] Handling signal: term
2025-11-23T17:31:39.312156374Z [2025-11-23 17:31:39 +0000] [207] [INFO] Worker exiting (pid: 207)
2025-11-23T17:31:41.13493203Z [2025-11-23 17:31:41 +0000] [56] [INFO] Shutting down: Master
2025-11-23T17:35:23.956385797Z 127.0.0.1 - - [23/Nov/2025:17:35:23 +0000] "GET / HTTP/1.1" 200 4875 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36"
2025-11-23T17:35:24.033130281Z 127.0.0.1 - - [23/Nov/2025:17:35:24 +0000] "GET /static/css/styles.css?v=3 HTTP/1.1" 200 0 "https://home-studio-recording.onrender.com/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36"
2025-11-23T17:35:24.035146616Z 127.0.0.1 - - [23/Nov/2025:17:35:24 +0000] "GET /static/js/app.js HTTP/1.1" 200 0 "https://home-studio-recording.onrender.com/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36"
2025-11-23T17:35:38.211112585Z ==> Detected service running on port 10000
2025-11-23T17:35:38.649813114Z ==> Docs on specifying a port: https://render.com/docs/web-services#port-binding
2025-11-23T17:36:00.01575882Z [2025-11-23 17:36:00 +0000] [56] [CRITICAL] WORKER TIMEOUT (pid:65)
2025-11-23T17:36:00.241568772Z [2025-11-23 17:36:00 +0000] [65] [ERROR] Error handling request /api/ask
2025-11-23T17:36:00.241588932Z Traceback (most recent call last):
2025-11-23T17:36:00.241594412Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/gunicorn/workers/sync.py", line 134, in handle
2025-11-23T17:36:00.241601093Z     self.handle_request(listener, req, client, addr)
2025-11-23T17:36:00.241605313Z     ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:36:00.241609863Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/gunicorn/workers/sync.py", line 177, in handle_request
2025-11-23T17:36:00.241613873Z     respiter = self.wsgi(environ, resp.start_response)
2025-11-23T17:36:00.241618323Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/flask/app.py", line 1536, in __call__
2025-11-23T17:36:00.241622063Z     return self.wsgi_app(environ, start_response)
2025-11-23T17:36:00.241625933Z            ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:36:00.241629963Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/flask/app.py", line 1511, in wsgi_app
2025-11-23T17:36:00.241633803Z     response = self.full_dispatch_request()
2025-11-23T17:36:00.241637753Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/flask/app.py", line 917, in full_dispatch_request
2025-11-23T17:36:00.241642444Z     rv = self.dispatch_request()
2025-11-23T17:36:00.241646604Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/flask/app.py", line 902, in dispatch_request
2025-11-23T17:36:00.241650634Z     return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
2025-11-23T17:36:00.241655464Z            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
2025-11-23T17:36:00.241660034Z   File "/opt/render/project/src/app.py", line 46, in ask_question
2025-11-23T17:36:00.241664374Z     result = service.answer_question(question, top_k=top_k)
2025-11-23T17:36:00.241670204Z   File "/opt/render/project/src/question_answering.py", line 702, in answer_question
2025-11-23T17:36:00.241674334Z     retrieved = self.index.retrieve(question, top_k=top_k)
2025-11-23T17:36:00.241686645Z   File "/opt/render/project/src/question_answering.py", line 398, in retrieve
2025-11-23T17:36:00.241688525Z     self._ensure_embeddings()
2025-11-23T17:36:00.241690305Z     ~~~~~~~~~~~~~~~~~~~~~~~^^
2025-11-23T17:36:00.241692485Z   File "/opt/render/project/src/question_answering.py", line 197, in _ensure_embeddings
2025-11-23T17:36:00.241694265Z     self.embeddings = self.embedding_backend.embed_texts(texts, task_type="retrieval_document")
2025-11-23T17:36:00.241695975Z                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:36:00.241697665Z   File "/opt/render/project/src/gemini_embeddings.py", line 52, in embed_texts
2025-11-23T17:36:00.241699425Z     result = genai.embed_content(
2025-11-23T17:36:00.241701195Z         model=self.model_name,
2025-11-23T17:36:00.241703355Z         content=text,
2025-11-23T17:36:00.241705175Z         task_type=task_type
2025-11-23T17:36:00.241706875Z     )
2025-11-23T17:36:00.241708735Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/generativeai/embedding.py", line 213, in embed_content
2025-11-23T17:36:00.241710525Z     embedding_response = client.embed_content(
2025-11-23T17:36:00.241712235Z         embedding_request,
2025-11-23T17:36:00.241713905Z         **request_options,
2025-11-23T17:36:00.241715635Z     )
2025-11-23T17:36:00.241717955Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 1263, in embed_content
2025-11-23T17:36:00.241719655Z     response = rpc(
2025-11-23T17:36:00.241721345Z         request,
2025-11-23T17:36:00.241723086Z     ...<2 lines>...
2025-11-23T17:36:00.241724855Z         metadata=metadata,
2025-11-23T17:36:00.241726535Z     )
2025-11-23T17:36:00.241728295Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
2025-11-23T17:36:00.241730035Z     return wrapped_func(*args, **kwargs)
2025-11-23T17:36:00.241732356Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
2025-11-23T17:36:00.241734046Z     return retry_target(
2025-11-23T17:36:00.241735726Z         target,
2025-11-23T17:36:00.241737376Z     ...<3 lines>...
2025-11-23T17:36:00.241739056Z         on_error=on_error,
2025-11-23T17:36:00.241740946Z     )
2025-11-23T17:36:00.241742636Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
2025-11-23T17:36:00.241744346Z     result = target()
2025-11-23T17:36:00.241746106Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
2025-11-23T17:36:00.241747846Z     return func(*args, **kwargs)
2025-11-23T17:36:00.241749506Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/api_core/grpc_helpers.py", line 75, in error_remapped_callable
2025-11-23T17:36:00.241751246Z     return callable_(*args, **kwargs)
2025-11-23T17:36:00.241753116Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/grpc/_interceptor.py", line 276, in __call__
2025-11-23T17:36:00.241754796Z     response, ignored_call = self._with_call(
2025-11-23T17:36:00.241756466Z                              ~~~~~~~~~~~~~~~^
2025-11-23T17:36:00.241758136Z         request,
2025-11-23T17:36:00.241759816Z         ^^^^^^^^
2025-11-23T17:36:00.241761456Z     ...<4 lines>...
2025-11-23T17:36:00.241763146Z         compression=compression,
2025-11-23T17:36:00.241764816Z         ^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:36:00.241769376Z     )
2025-11-23T17:36:00.241771136Z     ^
2025-11-23T17:36:00.241772867Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/grpc/_interceptor.py", line 328, in _with_call
2025-11-23T17:36:00.241774567Z     call = self._interceptor.intercept_unary_unary(
2025-11-23T17:36:00.241782647Z Loading dataset from processed_data.json...
2025-11-23T17:36:00.241783917Z         continuation, client_call_details, request
2025-11-23T17:36:00.241786307Z     )
2025-11-23T17:36:00.241789247Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py", line 79, in intercept_unary_unary
2025-11-23T17:36:00.241791027Z     response = continuation(client_call_details, request)
2025-11-23T17:36:00.241814428Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/grpc/_interceptor.py", line 314, in continuation
2025-11-23T17:36:00.241817537Z     response, call = self._thunk(new_method).with_call(
2025-11-23T17:36:00.241820357Z                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
2025-11-23T17:36:00.241823008Z         request,
2025-11-23T17:36:00.241825438Z         ^^^^^^^^
2025-11-23T17:36:00.241828298Z     ...<4 lines>...
2025-11-23T17:36:00.241830988Z         compression=new_compression,
2025-11-23T17:36:00.241834008Z         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:36:00.241837098Z     )
2025-11-23T17:36:00.241839558Z     ^
2025-11-23T17:36:00.241841398Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/grpc/_channel.py", line 1177, in with_call
2025-11-23T17:36:00.241843298Z     state, call = self._blocking(
2025-11-23T17:36:00.241844948Z                   ~~~~~~~~~~~~~~^
2025-11-23T17:36:00.241846728Z         request, timeout, metadata, credentials, wait_for_ready, compression
2025-11-23T17:36:00.241848468Z         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:36:00.241850138Z     )
2025-11-23T17:36:00.241851798Z     ^
2025-11-23T17:36:00.241853538Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/grpc/_channel.py", line 1150, in _blocking
2025-11-23T17:36:00.241855298Z     event = call.next_event()
2025-11-23T17:36:00.241857078Z   File "src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi", line 388, in grpc._cython.cygrpc.SegregatedCall.next_event
2025-11-23T17:36:00.241858829Z   File "src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi", line 211, in grpc._cython.cygrpc._next_call_event
2025-11-23T17:36:00.241860509Z   File "src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi", line 205, in grpc._cython.cygrpc._next_call_event
2025-11-23T17:36:00.241862189Z   File "src/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi", line 97, in grpc._cython.cygrpc._latent_event
2025-11-23T17:36:00.241863898Z   File "src/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi", line 80, in grpc._cython.cygrpc._internal_latent_event
2025-11-23T17:36:00.241865569Z   File "src/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi", line 61, in grpc._cython.cygrpc._next
2025-11-23T17:36:00.241867249Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/gunicorn/workers/base.py", line 204, in handle_abort
2025-11-23T17:36:00.241868979Z     sys.exit(1)
2025-11-23T17:36:00.241870729Z     ~~~~~~~~^^^
2025-11-23T17:36:00.241872419Z SystemExit: 1
2025-11-23T17:36:00.241877489Z Dataset loaded successfully!
2025-11-23T17:36:00.241879289Z ‚úì Loaded 71 cached answers from qa_history.jsonl
2025-11-23T17:36:00.241880959Z ‚úì Gemini backend initialized (model: gemini-2.5-flash-lite)
2025-11-23T17:36:00.241882879Z ‚ö†Ô∏è GitHub fallback not available: GitHub token not found. Set GITHUB_TOKEN environment variable or pass api_key parameter. Create token at: https://github.com/settings/tokens
2025-11-23T17:36:00.241888889Z ‚è≥ Generating embeddings for 438 passages via Gemini API...
2025-11-23T17:36:00.241890649Z    This happens only once (first query), then cached in memory.
2025-11-23T17:36:00.241892489Z ‚úì Gemini Embeddings initialized (model: models/text-embedding-004)
2025-11-23T17:36:00.241894229Z   Embedded 100/438 texts...
2025-11-23T17:36:00.241896049Z 127.0.0.1 - - [23/Nov/2025:17:36:00 +0000] "POST /api/ask HTTP/1.1" 500 0 "-" "-"
2025-11-23T17:36:00.242046293Z [2025-11-23 17:36:00 +0000] [65] [INFO] Worker exiting (pid: 65)
2025-11-23T17:36:01.112322671Z [2025-11-23 17:36:01 +0000] [56] [ERROR] Worker (pid:65) was sent SIGKILL! Perhaps out of memory?
2025-11-23T17:36:01.11671256Z [2025-11-23 17:36:01 +0000] [199] [INFO] Booting worker with pid: 199
2025-11-23T17:36:44.248372119Z [2025-11-23 17:36:44 +0000] [56] [CRITICAL] WORKER TIMEOUT (pid:199)
2025-11-23T17:36:44.383556046Z [2025-11-23 17:36:44 +0000] [199] [ERROR] Error handling request /api/ask
2025-11-23T17:36:44.383590927Z Traceback (most recent call last):
2025-11-23T17:36:44.383598677Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/gunicorn/workers/sync.py", line 134, in handle
2025-11-23T17:36:44.383603157Z     self.handle_request(listener, req, client, addr)
2025-11-23T17:36:44.383606957Z     ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:36:44.383610507Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/gunicorn/workers/sync.py", line 177, in handle_request
2025-11-23T17:36:44.383614117Z     respiter = self.wsgi(environ, resp.start_response)
2025-11-23T17:36:44.383618217Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/flask/app.py", line 1536, in __call__
2025-11-23T17:36:44.383621697Z     return self.wsgi_app(environ, start_response)
2025-11-23T17:36:44.383625217Z            ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:36:44.383628728Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/flask/app.py", line 1511, in wsgi_app
2025-11-23T17:36:44.383632268Z     response = self.full_dispatch_request()
2025-11-23T17:36:44.383635878Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/flask/app.py", line 917, in full_dispatch_request
2025-11-23T17:36:44.383640168Z     rv = self.dispatch_request()
2025-11-23T17:36:44.383643728Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/flask/app.py", line 902, in dispatch_request
2025-11-23T17:36:44.383647258Z     return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
2025-11-23T17:36:44.383650768Z            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
2025-11-23T17:36:44.383654568Z   File "/opt/render/project/src/app.py", line 46, in ask_question
2025-11-23T17:36:44.383658128Z     result = service.answer_question(question, top_k=top_k)
2025-11-23T17:36:44.383665609Z   File "/opt/render/project/src/question_answering.py", line 702, in answer_question
2025-11-23T17:36:44.383669229Z     retrieved = self.index.retrieve(question, top_k=top_k)
2025-11-23T17:36:44.383672769Z   File "/opt/render/project/src/question_answering.py", line 398, in retrieve
2025-11-23T17:36:44.383676289Z     self._ensure_embeddings()
2025-11-23T17:36:44.383679759Z     ~~~~~~~~~~~~~~~~~~~~~~~^^
2025-11-23T17:36:44.383683269Z   File "/opt/render/project/src/question_answering.py", line 197, in _ensure_embeddings
2025-11-23T17:36:44.383686769Z     self.embeddings = self.embedding_backend.embed_texts(texts, task_type="retrieval_document")
2025-11-23T17:36:44.383703599Z                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:36:44.383705819Z   File "/opt/render/project/src/gemini_embeddings.py", line 52, in embed_texts
2025-11-23T17:36:44.38370799Z     result = genai.embed_content(
2025-11-23T17:36:44.383710159Z         model=self.model_name,
2025-11-23T17:36:44.383712739Z         content=text,
2025-11-23T17:36:44.38371491Z         task_type=task_type
2025-11-23T17:36:44.38371707Z     )
2025-11-23T17:36:44.38371938Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/generativeai/embedding.py", line 213, in embed_content
2025-11-23T17:36:44.38372157Z     embedding_response = client.embed_content(
2025-11-23T17:36:44.38372368Z         embedding_request,
2025-11-23T17:36:44.38372622Z         **request_options,
2025-11-23T17:36:44.38372837Z     )
2025-11-23T17:36:44.38373181Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py", line 1263, in embed_content
2025-11-23T17:36:44.38373473Z     response = rpc(
2025-11-23T17:36:44.38373723Z         request,
2025-11-23T17:36:44.38373944Z     ...<2 lines>...
2025-11-23T17:36:44.38374155Z         metadata=metadata,
2025-11-23T17:36:44.38374366Z     )
2025-11-23T17:36:44.3837459Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py", line 131, in __call__
2025-11-23T17:36:44.38374811Z     return wrapped_func(*args, **kwargs)
2025-11-23T17:36:44.38375076Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py", line 294, in retry_wrapped_func
2025-11-23T17:36:44.38375288Z     return retry_target(
2025-11-23T17:36:44.383755031Z         target,
2025-11-23T17:36:44.38375716Z     ...<3 lines>...
2025-11-23T17:36:44.38375928Z         on_error=on_error,
2025-11-23T17:36:44.383761371Z     )
2025-11-23T17:36:44.383763741Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py", line 147, in retry_target
2025-11-23T17:36:44.383768521Z     result = target()
2025-11-23T17:36:44.383772301Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/api_core/timeout.py", line 130, in func_with_timeout
2025-11-23T17:36:44.383776281Z     return func(*args, **kwargs)
2025-11-23T17:36:44.383779581Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/api_core/grpc_helpers.py", line 75, in error_remapped_callable
2025-11-23T17:36:44.383782951Z     return callable_(*args, **kwargs)
2025-11-23T17:36:44.383786221Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/grpc/_interceptor.py", line 276, in __call__
2025-11-23T17:36:44.383789981Z     response, ignored_call = self._with_call(
2025-11-23T17:36:44.383815072Z                              ~~~~~~~~~~~~~~~^
2025-11-23T17:36:44.383817592Z         request,
2025-11-23T17:36:44.383819712Z         ^^^^^^^^
2025-11-23T17:36:44.383821762Z     ...<4 lines>...
2025-11-23T17:36:44.383823882Z         compression=compression,
2025-11-23T17:36:44.383826172Z         ^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:36:44.383828282Z     )
2025-11-23T17:36:44.383828672Z Loading dataset from processed_data.json...
2025-11-23T17:36:44.383830432Z     ^
2025-11-23T17:36:44.383833932Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/grpc/_interceptor.py", line 328, in _with_call
2025-11-23T17:36:44.383836312Z     call = self._interceptor.intercept_unary_unary(
2025-11-23T17:36:44.383845233Z         continuation, client_call_details, request
2025-11-23T17:36:44.383847533Z     )
2025-11-23T17:36:44.383850413Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py", line 79, in intercept_unary_unary
2025-11-23T17:36:44.383859993Z     response = continuation(client_call_details, request)
2025-11-23T17:36:44.383869993Z Dataset loaded successfully!
2025-11-23T17:36:44.383874833Z ‚úì Loaded 71 cached answers from qa_history.jsonl
2025-11-23T17:36:44.383878003Z ‚úì Gemini backend initialized (model: gemini-2.5-flash-lite)
2025-11-23T17:36:44.383881553Z ‚ö†Ô∏è GitHub fallback not available: GitHub token not found. Set GITHUB_TOKEN environment variable or pass api_key parameter. Create token at: https://github.com/settings/tokens
2025-11-23T17:36:44.383884253Z ‚è≥ Generating embeddings for 438 passages via Gemini API...
2025-11-23T17:36:44.383886583Z    This happens only once (first query), then cached in memory.
2025-11-23T17:36:44.383889523Z ‚úì Gemini Embeddings initialized (model: models/text-embedding-004)
2025-11-23T17:36:44.383891943Z   Embedded 100/438 texts...
2025-11-23T17:36:44.383895404Z 127.0.0.1 - - [23/Nov/2025:17:36:44 +0000] "POST /api/ask HTTP/1.1" 500 0 "-" "-"
2025-11-23T17:36:44.383917524Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/grpc/_interceptor.py", line 314, in continuation
2025-11-23T17:36:44.383922144Z     response, call = self._thunk(new_method).with_call(
2025-11-23T17:36:44.383924774Z                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
2025-11-23T17:36:44.383927314Z         request,
2025-11-23T17:36:44.383929675Z         ^^^^^^^^
2025-11-23T17:36:44.383932515Z     ...<4 lines>...
2025-11-23T17:36:44.383934895Z         compression=new_compression,
2025-11-23T17:36:44.383937164Z         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:36:44.383939795Z     )
2025-11-23T17:36:44.383942265Z     ^
2025-11-23T17:36:44.383945515Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/grpc/_channel.py", line 1177, in with_call
2025-11-23T17:36:44.383948165Z     state, call = self._blocking(
2025-11-23T17:36:44.383950875Z                   ~~~~~~~~~~~~~~^
2025-11-23T17:36:44.383953665Z         request, timeout, metadata, credentials, wait_for_ready, compression
2025-11-23T17:36:44.383956165Z         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-23T17:36:44.383958355Z     )
2025-11-23T17:36:44.383960555Z     ^
2025-11-23T17:36:44.383962645Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/grpc/_channel.py", line 1150, in _blocking
2025-11-23T17:36:44.383965275Z     event = call.next_event()
2025-11-23T17:36:44.383967565Z   File "src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi", line 388, in grpc._cython.cygrpc.SegregatedCall.next_event
2025-11-23T17:36:44.383969725Z   File "src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi", line 211, in grpc._cython.cygrpc._next_call_event
2025-11-23T17:36:44.383971995Z   File "src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi", line 205, in grpc._cython.cygrpc._next_call_event
2025-11-23T17:36:44.383974145Z   File "src/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi", line 97, in grpc._cython.cygrpc._latent_event
2025-11-23T17:36:44.383976405Z   File "src/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi", line 80, in grpc._cython.cygrpc._internal_latent_event
2025-11-23T17:36:44.383978756Z   File "src/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi", line 61, in grpc._cython.cygrpc._next
2025-11-23T17:36:44.383981265Z   File "/opt/render/project/src/.venv/lib/python3.13/site-packages/gunicorn/workers/base.py", line 204, in handle_abort
2025-11-23T17:36:44.383992016Z     sys.exit(1)
2025-11-23T17:36:44.383994706Z     ~~~~~~~~^^^
2025-11-23T17:36:44.383997256Z SystemExit: 1
2025-11-23T17:36:44.384100028Z [2025-11-23 17:36:44 +0000] [199] [INFO] Worker exiting (pid: 199)
2025-11-23T17:36:45.318033066Z [2025-11-23 17:36:45 +0000] [56] [ERROR] Worker (pid:199) was sent SIGKILL! Perhaps out of memory?
2025-11-23T17:36:45.409331927Z [2025-11-23 17:36:45 +0000] [342] [INFO] Booting worker with pid: 342